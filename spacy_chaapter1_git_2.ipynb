{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802f54fc",
   "metadata": {},
   "source": [
    "### Refrence is https://course.spacy.io/en/chapter1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"It costs $5.\")\n",
    "for token in doc :\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ffff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index:   \", [token.i for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index:   \", [token.i for token in doc])\n",
    "print(\"Text:    \", [token.text for token in doc])\n",
    "\n",
    "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:\", [token.is_punct for token in doc])\n",
    "print(\"like_num:\", [token.like_num for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3cdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# Select the first token\n",
    "first_token = doc[0]\n",
    "\n",
    "# Print the first token's text\n",
    "print(first_token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9073ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7217d",
   "metadata": {},
   "source": [
    "## lexical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afefb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "In this example, you’ll use spaCy’s Doc and Token objects,\n",
    "and lexical attributes to find percentages in a text. You’ll be looking for two subsequent tokens: a number\n",
    "and a percent sign.\n",
    "\n",
    "Use the like_num token attribute to check whether a token in the doc resembles a number.\n",
    "Get the token following the current token in the document. The index of the next token in the doc is token.i + 1.\n",
    "Check whether the next token’s text attribute is a percent sign ”%“.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41487017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text\n",
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i + 1]\n",
    "        # Check if the next token's text equals \"%\"\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a2616",
   "metadata": {},
   "source": [
    "## Trained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316c14d",
   "metadata": {},
   "source": [
    "## Predicting Part-of-speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each token in the doc, we can print the text and\n",
    "# the .pos_ attribute, the predicted part-of-speech tag.\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the small English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"She ate the pizza\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Print the text and the predicted part-of-speech tag\n",
    "    print(token.text, token.pos_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
